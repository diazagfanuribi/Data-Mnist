{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Logistic Regression (data mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils\n",
    "import numpy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# load (downloaded if needed) the MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# plot 4 images as gray scale\n",
    "plt.subplot(221)\n",
    "plt.imshow(X_test[0], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(222)\n",
    "plt.imshow(X_test[1], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(223)\n",
    "plt.imshow(X_test[2], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(224)\n",
    "plt.imshow(X_test[3], cmap=plt.get_cmap('gray'))\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### flatten array 28*28 images to a 784 vector for each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
    "X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], num_pixels).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize data from 0-255 to 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model(input_dim, output_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(output_dim, input_dim=input_dim, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = baseline_model(784,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 1.4499 - acc: 0.6641 - val_loss: 0.9691 - val_acc: 0.8255\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.8457 - acc: 0.8297 - val_loss: 0.7125 - val_acc: 0.8533\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.6809 - acc: 0.8488 - val_loss: 0.6070 - val_acc: 0.8676\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.6011 - acc: 0.8584 - val_loss: 0.5475 - val_acc: 0.8755\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.5525 - acc: 0.8657 - val_loss: 0.5090 - val_acc: 0.8785\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.5192 - acc: 0.8702 - val_loss: 0.4815 - val_acc: 0.8826\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.4947 - acc: 0.8744 - val_loss: 0.4606 - val_acc: 0.8861\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.4756 - acc: 0.8778 - val_loss: 0.4441 - val_acc: 0.8880\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.4603 - acc: 0.8809 - val_loss: 0.4307 - val_acc: 0.8899\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.4476 - acc: 0.8829 - val_loss: 0.4195 - val_acc: 0.8920\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.4369 - acc: 0.8850 - val_loss: 0.4101 - val_acc: 0.8934\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.4277 - acc: 0.8865 - val_loss: 0.4019 - val_acc: 0.8950\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.4197 - acc: 0.8885 - val_loss: 0.3948 - val_acc: 0.8964\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.4126 - acc: 0.8894 - val_loss: 0.3883 - val_acc: 0.8970\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.4063 - acc: 0.8907 - val_loss: 0.3829 - val_acc: 0.8991\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.4007 - acc: 0.8915 - val_loss: 0.3777 - val_acc: 0.8998\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.3956 - acc: 0.8926 - val_loss: 0.3735 - val_acc: 0.9017\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.3909 - acc: 0.8939 - val_loss: 0.3691 - val_acc: 0.9025\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.3867 - acc: 0.8949 - val_loss: 0.3652 - val_acc: 0.9025\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.3827 - acc: 0.8954 - val_loss: 0.3617 - val_acc: 0.9034\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.3791 - acc: 0.8963 - val_loss: 0.3586 - val_acc: 0.9042\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.3757 - acc: 0.8973 - val_loss: 0.3555 - val_acc: 0.9052\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.3726 - acc: 0.8976 - val_loss: 0.3526 - val_acc: 0.9059\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.3697 - acc: 0.8984 - val_loss: 0.3500 - val_acc: 0.9058\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.3669 - acc: 0.8991 - val_loss: 0.3475 - val_acc: 0.9062\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.3643 - acc: 0.8998 - val_loss: 0.3455 - val_acc: 0.9068\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.3619 - acc: 0.9003 - val_loss: 0.3433 - val_acc: 0.9074\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.3596 - acc: 0.9008 - val_loss: 0.3411 - val_acc: 0.9083\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.3574 - acc: 0.9014 - val_loss: 0.3394 - val_acc: 0.9083\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.3553 - acc: 0.9019 - val_loss: 0.3375 - val_acc: 0.9090\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.3534 - acc: 0.9024 - val_loss: 0.3358 - val_acc: 0.9094\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.3515 - acc: 0.9029 - val_loss: 0.3341 - val_acc: 0.9087\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.3497 - acc: 0.9034 - val_loss: 0.3326 - val_acc: 0.9100\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.3480 - acc: 0.9036 - val_loss: 0.3312 - val_acc: 0.9100\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.3464 - acc: 0.9041 - val_loss: 0.3296 - val_acc: 0.9101\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.3448 - acc: 0.9043 - val_loss: 0.3282 - val_acc: 0.9108\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.3433 - acc: 0.9045 - val_loss: 0.3271 - val_acc: 0.9106\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.3419 - acc: 0.9052 - val_loss: 0.3258 - val_acc: 0.9111\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.3405 - acc: 0.9055 - val_loss: 0.3247 - val_acc: 0.9111\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.3392 - acc: 0.9057 - val_loss: 0.3236 - val_acc: 0.9115\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.3379 - acc: 0.9062 - val_loss: 0.3225 - val_acc: 0.9120\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.3366 - acc: 0.9067 - val_loss: 0.3212 - val_acc: 0.9121\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.3354 - acc: 0.9068 - val_loss: 0.3202 - val_acc: 0.9124\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.3343 - acc: 0.9073 - val_loss: 0.3193 - val_acc: 0.9123\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.3332 - acc: 0.9071 - val_loss: 0.3184 - val_acc: 0.9131\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.3321 - acc: 0.9078 - val_loss: 0.3174 - val_acc: 0.9135\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.3311 - acc: 0.9079 - val_loss: 0.3166 - val_acc: 0.9141\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.3301 - acc: 0.9081 - val_loss: 0.3157 - val_acc: 0.9140\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.3291 - acc: 0.9087 - val_loss: 0.3148 - val_acc: 0.9142\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.3281 - acc: 0.9091 - val_loss: 0.3140 - val_acc: 0.9143\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.3272 - acc: 0.9092 - val_loss: 0.3132 - val_acc: 0.9145\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.3263 - acc: 0.9092 - val_loss: 0.3125 - val_acc: 0.9148\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.3254 - acc: 0.9095 - val_loss: 0.3117 - val_acc: 0.9148\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.3246 - acc: 0.9095 - val_loss: 0.3112 - val_acc: 0.9148\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.3237 - acc: 0.9097 - val_loss: 0.3107 - val_acc: 0.9153\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.3230 - acc: 0.9101 - val_loss: 0.3098 - val_acc: 0.9152\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.3222 - acc: 0.9102 - val_loss: 0.3091 - val_acc: 0.9153\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.3214 - acc: 0.9105 - val_loss: 0.3085 - val_acc: 0.9157\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.3207 - acc: 0.9106 - val_loss: 0.3079 - val_acc: 0.9153\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.3200 - acc: 0.9111 - val_loss: 0.3072 - val_acc: 0.9156\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.3193 - acc: 0.9112 - val_loss: 0.3067 - val_acc: 0.9161\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.3185 - acc: 0.9114 - val_loss: 0.3062 - val_acc: 0.9156\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.3179 - acc: 0.9115 - val_loss: 0.3056 - val_acc: 0.9161\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.3172 - acc: 0.9118 - val_loss: 0.3051 - val_acc: 0.9162\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.3166 - acc: 0.9119 - val_loss: 0.3047 - val_acc: 0.9166\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.3160 - acc: 0.9121 - val_loss: 0.3042 - val_acc: 0.9167\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.3153 - acc: 0.9124 - val_loss: 0.3036 - val_acc: 0.9165\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.3147 - acc: 0.9125 - val_loss: 0.3031 - val_acc: 0.9169\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.3141 - acc: 0.9130 - val_loss: 0.3027 - val_acc: 0.9169\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.3136 - acc: 0.9129 - val_loss: 0.3024 - val_acc: 0.9176\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.3130 - acc: 0.9130 - val_loss: 0.3018 - val_acc: 0.9170\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.3125 - acc: 0.9132 - val_loss: 0.3012 - val_acc: 0.9175\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.3119 - acc: 0.9134 - val_loss: 0.3009 - val_acc: 0.9174\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.3114 - acc: 0.9134 - val_loss: 0.3004 - val_acc: 0.9176\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.3109 - acc: 0.9139 - val_loss: 0.3000 - val_acc: 0.9178\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.3103 - acc: 0.9140 - val_loss: 0.2995 - val_acc: 0.9176\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.3099 - acc: 0.9138 - val_loss: 0.2992 - val_acc: 0.9179\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.3094 - acc: 0.9141 - val_loss: 0.2987 - val_acc: 0.9179\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.3089 - acc: 0.9143 - val_loss: 0.2985 - val_acc: 0.9180\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.3084 - acc: 0.9144 - val_loss: 0.2981 - val_acc: 0.9182\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.3079 - acc: 0.9146 - val_loss: 0.2976 - val_acc: 0.9178\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.3075 - acc: 0.9145 - val_loss: 0.2973 - val_acc: 0.9181\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.3070 - acc: 0.9151 - val_loss: 0.2970 - val_acc: 0.9185\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.3066 - acc: 0.9150 - val_loss: 0.2967 - val_acc: 0.9185\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.3062 - acc: 0.9151 - val_loss: 0.2964 - val_acc: 0.9185\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.3057 - acc: 0.9153 - val_loss: 0.2960 - val_acc: 0.9185\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.3053 - acc: 0.9152 - val_loss: 0.2957 - val_acc: 0.9184\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.3049 - acc: 0.9154 - val_loss: 0.2954 - val_acc: 0.9181\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.3045 - acc: 0.9156 - val_loss: 0.2951 - val_acc: 0.9184\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.3041 - acc: 0.9154 - val_loss: 0.2949 - val_acc: 0.9183\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.3037 - acc: 0.9159 - val_loss: 0.2946 - val_acc: 0.9186\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.3033 - acc: 0.9158 - val_loss: 0.2941 - val_acc: 0.9182\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.3029 - acc: 0.9160 - val_loss: 0.2939 - val_acc: 0.9189\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.3025 - acc: 0.9159 - val_loss: 0.2936 - val_acc: 0.9187\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.3022 - acc: 0.9161 - val_loss: 0.2934 - val_acc: 0.9187\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.3018 - acc: 0.9162 - val_loss: 0.2931 - val_acc: 0.9187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100\n",
      " - 1s - loss: 0.3015 - acc: 0.9164 - val_loss: 0.2929 - val_acc: 0.9189\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.3011 - acc: 0.9164 - val_loss: 0.2925 - val_acc: 0.9187\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.3008 - acc: 0.9165 - val_loss: 0.2922 - val_acc: 0.9192\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.3004 - acc: 0.9164 - val_loss: 0.2921 - val_acc: 0.9189\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a493e2b6a0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=200, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model peformances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Error: 16.26%\n"
     ]
    }
   ],
   "source": [
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ynew=model.predict_classes(X_test[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test[0], Prediksi=7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_test1=X_test*255\n",
    "X_test1=X_test1.reshape(10000,28,28)\n",
    "for i in range(1):\n",
    "    print(\"X_test%s, Prediksi=%s\" % ([i], ynew[i]))\n",
    "    plt.imshow(X_test1[i], cmap=plt.get_cmap('gray'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
